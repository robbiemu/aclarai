# ClarifAI Environment Variables Configuration
# Copy this file to .env and modify the values as needed
#
# This file contains all environment variables used by ClarifAI services.
# Variables are automatically loaded using python-dotenv at service startup.
# For external database connections, see the "External Database Configuration" section below.

# === Database Configuration ===

# PostgreSQL (Vector DB) Configuration
# Used for storing sentence embeddings and vector similarity search
POSTGRES_USER=clarifai
POSTGRES_PASSWORD=your_postgres_password_here
POSTGRES_DB=clarifai
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Neo4j (Knowledge Graph) Configuration  
# Used for storing claims, concepts, summaries, and relationships
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password_here
NEO4J_HOST=neo4j
NEO4J_HTTP_PORT=7474
NEO4J_BOLT_PORT=7687

# === Message Broker Configuration ===

# RabbitMQ Configuration
# Used for inter-service communication and job queuing
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_USER=user
RABBITMQ_PASSWORD=your_rabbitmq_password_here
RABBITMQ_MANAGEMENT_PORT=15672

# === Service Configuration ===

# Vault Configuration
# Path where Markdown files are stored and monitored
VAULT_PATH=/vault

# ClarifAI Core Service
CLARIFAI_CORE_HOST=clarifai-core
CLARIFAI_CORE_PORT=8000

# ClarifAI UI Service
CLARIFAI_UI_HOST=0.0.0.0
CLARIFAI_UI_PORT=7860
CLARIFAI_UI_DEBUG=false

# === External Database Configuration ===
# Enable these settings to use external databases instead of Docker services
# When using external databases running on the Docker host, the system will
# automatically use 'host.docker.internal' when running inside Docker containers

# External PostgreSQL Configuration
# Uncomment these lines to use an external PostgreSQL instance
# POSTGRES_HOST=host.docker.internal  # or your external PostgreSQL hostname/IP
# POSTGRES_PORT=5432
# POSTGRES_USER=your_external_postgres_user
# POSTGRES_PASSWORD=your_external_postgres_password
# POSTGRES_DB=clarifai

# External Neo4j Configuration  
# Uncomment these lines to use an external Neo4j instance
# NEO4J_HOST=host.docker.internal      # or your external Neo4j hostname/IP
# NEO4J_HTTP_PORT=7474
# NEO4J_BOLT_PORT=7687
# NEO4J_USER=neo4j
# NEO4J_PASSWORD=your_external_neo4j_password

# External RabbitMQ Configuration
# Uncomment these lines to use an external RabbitMQ instance
# RABBITMQ_HOST=host.docker.internal   # or your external RabbitMQ hostname/IP
# RABBITMQ_PORT=5672
# RABBITMQ_USER=your_external_rabbitmq_user  
# RABBITMQ_PASSWORD=your_external_rabbitmq_password

# === AI/ML Configuration ===

# Model Configuration
# Specify which AI models to use for different tasks
CLAIMIFY_MODEL=gpt-4
FALLBACK_PLUGIN=ollama:gemma:2b

# Threshold Configuration
# Adjust these values to fine-tune concept merging and claim linking
CONCEPT_MERGE_THRESHOLD=0.91
CLAIM_LINK_STRENGTH_THRESHOLD=0.60

# Window Configuration
# Control context window size for claim extraction
CLAIMIFY_WINDOW_PREVIOUS=3
CLAIMIFY_WINDOW_FOLLOWING=1

# === API Keys ===
# Required for AI model integration

# OpenAI API Key (required for GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (required for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# === Automation Configuration ===

# Automation Control
# Set to 'true' to pause all automated processing
AUTOMATION_PAUSE=false

# Scheduler Configuration
# Configure periodic jobs and maintenance tasks
CONCEPT_EMBEDDING_REFRESH_ENABLED=true
CONCEPT_EMBEDDING_REFRESH_CRON="0 3 * * *"
SENTENCE_SPLITTER_ENABLED=false

# === Logging Configuration ===

# Log Level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# Set to DEBUG for detailed logging during development
LOG_LEVEL=INFO

# === Security Configuration ===

# JWT Secret (IMPORTANT: change this in production!)
# Use a long, random string for production deployments
# Example: openssl rand -base64 32
JWT_SECRET=your_jwt_secret_here

# === Security Notes ===
# 
# This .env.example file uses placeholder values that are clearly marked
# as examples (e.g., "your_password_here"). For production:
#
# 1. Replace ALL placeholder values with real credentials
# 2. Use strong, unique passwords for each service
# 3. Store API keys securely and rotate them regularly
# 4. Never commit the actual .env file to version control
# 5. Use environment-specific .env files (.env.production, .env.staging)
#
# For secure password generation:
# - PostgreSQL: Use a strong password manager or: openssl rand -base64 32
# - Neo4j: Use a strong password manager or: openssl rand -base64 32  
# - RabbitMQ: Use a strong password manager or: openssl rand -base64 32
# - JWT Secret: openssl rand -base64 64

# === Development Configuration ===

# Development Mode
# Enable for additional debugging features
DEBUG=false

# Hot Reload
# Enable for automatic service restart on code changes
HOT_RELOAD=false

# Docker Container Detection
# This is automatically set by Docker - do not modify manually
# DOCKER_CONTAINER=true

# === Configuration Usage Notes ===
#
# 1. **Database Passwords**: POSTGRES_PASSWORD and NEO4J_PASSWORD are required
#    and must be set for the services to start successfully.
#
# 2. **External Databases**: When using external databases, the system will
#    automatically apply 'host.docker.internal' fallback when running in Docker.
#    You can also explicitly set the host to 'host.docker.internal'.
#
# 3. **Environment Variable Validation**: The system validates required variables
#    at startup and provides clear error messages for missing configuration.
#
# 4. **Security**: Never commit the .env file to version control. It contains
#    sensitive information like passwords and API keys.
#
# 5. **Docker Compose**: All services automatically load this .env file when
#    using 'docker compose up'. Individual variables can be overridden using
#    shell environment variables.
#
# 6. **Service Dependencies**: Some variables like VAULT_PATH and RABBITMQ_HOST
#    are used by multiple services for communication and shared resource access.