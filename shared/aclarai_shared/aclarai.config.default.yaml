# aclarai Default Configuration File
# This file contains the default values for all configurable parameters in the aclarai system
# Users can override these settings by creating a settings/aclarai.config.yaml file
# Following the architecture principle: Never hardcode values

# Version and system info
version: "0.1.0"
config_version: 1

# Database configurations
databases:
  postgres:
    # Connection settings (can be overridden by environment variables)
    host: "postgres"  # POSTGRES_HOST
    port: 5432        # POSTGRES_PORT
    database: "aclarai"  # POSTGRES_DB
    # User and password come from environment variables only
    # POSTGRES_USER, POSTGRES_PASSWORD
    
  neo4j:
    # Connection settings (can be overridden by environment variables)
    host: "neo4j"     # NEO4J_HOST
    port: 7687        # NEO4J_BOLT_PORT
    # User and password come from environment variables only
    # NEO4J_USER, NEO4J_PASSWORD

# Vault and path configurations
paths:
  vault: "/vault"
  tier1: "conversations"    # Relative to vault path
  tier2: "summaries"       # Relative to vault path
  tier3: "concepts"        # Relative to vault path
  settings: "/settings"

# Model configuration (following design_config_panel.md structure)
model:
  claimify:
    default: "gpt-3.5-turbo"
    selection: null      # Uses default if not specified
    disambiguation: null # Uses default if not specified  
    decomposition: null  # Uses default if not specified
  fallback_plugin: "gpt-3.5-turbo"

# Embedding configuration
embedding:
  # Models configuration
  models:
    default: "sentence-transformers/all-MiniLM-L6-v2"
    # Alternative models can be configured here
    # large: "sentence-transformers/all-mpnet-base-v2"
    # multilingual: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  
  # Embedding settings
  device: "auto"  # "auto", "cpu", "cuda", "mps"
  batch_size: 32
  
  # PGVector settings
  pgvector:
    collection_name: "utterances"
    embed_dim: 384  # Dimension for all-MiniLM-L6-v2
    # Index settings for pgvector
    index_type: "ivfflat"
    index_lists: 100  # Number of lists for IVFFlat index
  
  # Chunking configuration
  chunking:
    # SentenceSplitter parameters following on-sentence_splitting.md
    chunk_size: 300
    chunk_overlap: 30
    keep_separator: true
    
    # Post-processing rules for coherent chunks
    merge_colon_endings: true    # Merge "text:" + "continuation" 
    merge_short_prefixes: true   # Merge fragments < 5 tokens
    min_chunk_tokens: 5          # Minimum tokens per chunk

# Noun phrase extraction configuration
noun_phrase_extraction:
  # spaCy model to use for extraction
  spacy_model: "en_core_web_sm"  # or "en_core_web_trf" for better accuracy
  
  # Normalization settings
  min_phrase_length: 2        # Minimum characters after normalization
  filter_digits_only: true   # Skip phrases that are only digits
  
  # Vector storage settings for concept_candidates
  concept_candidates:
    collection_name: "concept_candidates"
    status_field: "status"      # Field name for tracking candidate status
    default_status: "pending"   # Initial status for new candidates

# Threshold configuration (following design_config_panel.md structure)
threshold:
  concept_merge: 0.90
  claim_link_strength: 0.60
  summary_grouping_similarity: 0.80  # Cosine similarity for grouping utterances for Tier 2 summaries

# Window configuration (following design_config_panel.md structure)
window:
  claimify:
    p: 3  # Previous sentences
    f: 1  # Following sentences

# Processing configuration
processing:
  # Global LLM parameters
  temperature: 0.1
  max_tokens: 1000
  timeout_seconds: 30
  
  # Claimify pipeline configuration
  claimify:
    max_retries: 3
    
    # Logging configuration
    logging:
      log_decisions: true
      log_transformations: true
      log_timing: true
      
  # Batch sizes for various operations
  batch_sizes:
    embedding: 50      # Documents to embed at once
    chunking: 100      # Documents to chunk at once
    
  # Retry configuration following on-error-handling-and-resilience.md
  retries:
    max_attempts: 3
    backoff_factor: 2
    max_wait_time: 60

# Concept detection configuration  
concepts:
  # Vector index settings for concept candidates
  candidates:
    collection_name: "concept_candidates"
    similarity_threshold: 0.9  # For detecting existing concepts
    
  # Canonical concepts vector store
  canonical:
    collection_name: "concepts"
    similarity_threshold: 0.95  # For merging similar concepts

# Logging configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "structured"  # "structured" or "simple"
  
  # Service identification for structured logs
  service_name: "aclarai"
  
  # Log to stdout/stderr following idea-logging.md
  handlers:
    - type: "console"
      stream: "stdout"

# Plugin configuration
plugins:
  # Plugin discovery and loading
  auto_discover: true
  plugin_directories:
    - "shared/aclarai_shared/plugins"
  
  # Default plugin settings
  default_plugin:
    enabled: true
    llm_fallback: true

# Scheduler configuration
scheduler:
  # Job configurations
  jobs:
    concept_embedding_refresh:
      enabled: true
      cron: "0 3 * * *"  # 3 AM daily
      description: "Refresh concept embeddings from Tier 3 pages"
    
    vault_sync:
      enabled: true
      cron: "*/30 * * * *"  # Every 30 minutes
      description: "Sync vault files with knowledge graph"

# Feature flags
features:
  # Sprint 2 features
  embedding_enabled: true
  chunking_enabled: true
  pgvector_enabled: true
  
  # Future features (disabled for MVP)
  evaluation_agents: false
  concept_linking: false
  tier2_generation: false

# Vault Watcher service configuration
vault_watcher:
  # File watching configuration
  watch:
    batch_interval: 2.0  # seconds to wait before processing batched events
    max_batch_size: 50   # maximum number of events to batch
    file_patterns:
      - "*.md"           # Only watch markdown files
    ignore_patterns:
      - ".*"             # Ignore hidden files
      - "*~"             # Ignore temporary files
      - "*.tmp"          # Ignore temp files
      - ".obsidian/*"    # Ignore Obsidian metadata
  
  # RabbitMQ configuration
  rabbitmq:
    queue_name: "aclarai_dirty_blocks"
    exchange: ""         # Use default exchange
    routing_key: "aclarai_dirty_blocks"
    durable: true        # Make queue persistent
    connection_timeout: 30  # seconds
    retry_attempts: 3
    retry_delay: 5       # seconds between retries

# Development and testing
development:
  debug: false
  test_mode: false
  mock_llm: false
  mock_embedding: false