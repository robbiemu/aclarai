tools:
  # --- Tool Definitions ---
  # These sections define the parameters for initializing each type of tool.
  neo4j:
    enabled: true
    retry_attempts: 3
    timeout_seconds: 30
    # URI, user, and password are read from the main `databases.neo4j` section.
  
  vector_search:
    enabled: true
    # Default parameters for any vector search tool instance.
    # Specific collections are defined per-agent in the mapping below.
    similarity_threshold: 0.7
    max_results: 5
  
  web_search:
    enabled: false  # Default to disabled for safety and to avoid API key errors.
    provider: "tavily"  # Default provider. Options: "tavily", "brave", etc.
    api_key_env_var: "TAVILY_API_KEY" # The environment variable holding the API key.
    timeout_seconds: 30
    max_results: 5

  # --- Agent-to-Tool Mapping ---
  # This section defines which tools are provided to each agent.
  # The ToolFactory will use this mapping to build the tool list.
  agent_tool_mappings:
    decontextualization_agent:
      - name: "VectorSearchTool"
        # Tool-specific parameters go here
        params:
          collection: "utterances"
          # Metadata for the agent's prompt
          metadata:
            name: "vector_search_utterances"
            description: >
              Searches for similar utterances in the knowledge base.
              Use this tool to find existing utterances that are semantically
              similar to the input claim. This helps determine if the claim
              is ambiguous or relies on unstated context by checking if
              very similar phrases appear in diverse contexts.
    entailment_agent:
      - name: "Neo4jQueryTool"
        params: {} # Uses default Neo4j connection
        metadata:
          name: "neo4j_query_tool"
          description: >
            Executes Cypher queries on the knowledge graph. Use this to
            retrieve contextual information, such as surrounding conversation
            blocks or related concepts, to better assess entailment.
      - name: "VectorSearchTool"
        params:
          collection: "utterances" # Or another relevant collection
        metadata:
          name: "vector_search_utterances"
          description: >
            Searches for similar utterances or text segments in the knowledge base.
            Use this to find supporting or contradictory evidence or to understand
            the typical usage of phrases found in the source or claim.
    
    # Example for another agent that might need multiple tools:
    # some_other_agent:
    #   - name: "Neo4jQueryTool"
    #   - name: "WebSearchTool"

# aclarai Default Configuration File
# This file contains the default values for all configurable parameters in the aclarai system
# Users can override these settings by creating a settings/aclarai.config.yaml file
# Following the architecture principle: Never hardcode values

# Version and system info
version: "0.1.0"
config_version: 1

# Database configurations
databases:
  postgres:
    # Connection settings (can be overridden by environment variables)
    host: "postgres"  # POSTGRES_HOST
    port: 5432        # POSTGRES_PORT
    database: "aclarai"  # POSTGRES_DB
    # User and password come from environment variables only
    # POSTGRES_USER, POSTGRES_PASSWORD
    
  neo4j:
    # Connection settings (can be overridden by environment variables)
    host: "neo4j"     # NEO4J_HOST
    port: 7687        # NEO4J_BOLT_PORT
    # User and password come from environment variables only
    # NEO4J_USER, NEO4J_PASSWORD

# Vault and path configurations
paths:
  vault: "/vault"
  tier1: "conversations"    # Relative to vault path
  tier2: "summaries"       # Relative to vault path
  tier3: "concepts"        # Relative to vault path
  settings: "/settings"

# Model configuration (following design_config_panel.md structure)
model:
  claimify:
    default: "gpt-3.5-turbo"
    selection: null      # Uses default if not specified
    disambiguation: null # Uses default if not specified  
    decomposition: null  # Uses default if not specified
    entailment: null     # Uses default if not specified (e.g., gpt-3.5-turbo)
  concept_linker: "gpt-3.5-turbo"
  concept_summary: "gpt-4"
  subject_summary: "gpt-3.5-turbo"
  trending_concepts_agent: "gpt-4"
  fallback_plugin: "gpt-3.5-turbo"

# Concept summary agent configuration
concept_summaries:
  model: "gpt-4"
  max_examples: 5
  skip_if_no_claims: true
  include_see_also: true

# Subject summary agent configuration (for concept clustering)
subject_summaries:
  model: "gpt-3.5-turbo"
  similarity_threshold: 0.92
  min_concepts: 3
  max_concepts: 15
  allow_web_search: true
  skip_if_incoherent: false

# Embedding configuration
embedding:
  # Models configuration (following design_config_panel.md structure)
  utterance: "sentence-transformers/all-MiniLM-L6-v2"
  concept: "text-embedding-3-small" 
  summary: "sentence-transformers/all-MiniLM-L6-v2"
  fallback: "sentence-transformers/all-mpnet-base-v2"
  
  # Legacy models configuration for backward compatibility
  models:
    default: "sentence-transformers/all-MiniLM-L6-v2"
    # Alternative models can be configured here
    # large: "sentence-transformers/all-mpnet-base-v2"
    # multilingual: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  
  # Embedding settings
  device: "auto"  # "auto", "cpu", "cuda", "mps"
  batch_size: 32
  
  # PGVector settings
  pgvector:
    collection_name: "utterances"
    embed_dim: 384  # Dimension for all-MiniLM-L6-v2
    # Index settings for pgvector
    index_type: "ivfflat"
    index_lists: 100  # Number of lists for IVFFlat index
  
  # Chunking configuration
  chunking:
    # SentenceSplitter parameters following on-sentence_splitting.md
    chunk_size: 300
    chunk_overlap: 30
    keep_separator: true
    
    # Post-processing rules for coherent chunks
    merge_colon_endings: true    # Merge "text:" + "continuation" 
    merge_short_prefixes: true   # Merge fragments < 5 tokens
    min_chunk_tokens: 5          # Minimum tokens per chunk

# Noun phrase extraction configuration
noun_phrase_extraction:
  # spaCy model to use for extraction
  spacy_model: "en_core_web_sm"  # or "en_core_web_trf" for better accuracy
  
  # Normalization settings
  min_phrase_length: 2        # Minimum characters after normalization
  filter_digits_only: true   # Skip phrases that are only digits
  
  # Vector storage settings for concept_candidates
  concept_candidates:
    collection_name: "concept_candidates"
    status_field: "status"      # Field name for tracking candidate status
    default_status: "pending"   # Initial status for new candidates

# Threshold configuration (following design_config_panel.md structure)
threshold:
  concept_merge: 0.90
  claim_link_strength: 0.60
  summary_grouping_similarity: 0.80  # Cosine similarity for grouping utterances for Tier 2 summaries
  claim_quality: 0.70  # Quality threshold for claim promotion and linking (geometric mean of evaluation scores)

# Window configuration (following design_config_panel.md structure)
window:
  claimify:
    p: 3  # Previous sentences
    f: 1  # Following sentences

# Processing configuration
processing:
  # Global LLM parameters
  temperature: 0.1
  max_tokens: 1000
  timeout_seconds: 30
  
  # Claimify pipeline configuration
  claimify:
    max_retries: 3
    
    # Logging configuration
    logging:
      log_decisions: true
      log_transformations: true
      log_timing: true
      
  # Batch sizes for various operations
  batch_sizes:
    embedding: 50      # Documents to embed at once
    chunking: 100      # Documents to chunk at once
    
  # Retry configuration following on-error-handling-and-resilience.md
  retries:
    max_attempts: 3
    backoff_factor: 2
    max_wait_time: 60

# Concept detection configuration  
concepts:
  # Vector index settings for concept candidates
  candidates:
    collection_name: "concept_candidates"
    similarity_threshold: 0.9  # For detecting existing concepts
    
  # Canonical concepts vector store
  canonical:
    collection_name: "concepts"
    similarity_threshold: 0.95  # For merging similar concepts

# Logging configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "structured"  # "structured" or "simple"
  
  # Service identification for structured logs
  service_name: "aclarai"
  
  # Log to stdout/stderr following idea-logging.md
  handlers:
    - type: "console"
      stream: "stdout"

# Plugin configuration
plugins:
  # Plugin discovery and loading
  auto_discover: true
  plugin_directories:
    - "shared/aclarai_shared/plugins"
  
  # Default plugin settings
  default_plugin:
    enabled: true
    llm_fallback: true

# Scheduler configuration
scheduler:
  # Job configurations
  jobs:
    concept_embedding_refresh:
      enabled: true
      manual_only: false
      cron: "0 3 * * *"  # 3 AM daily
      description: "Refresh concept embeddings from Tier 3 pages"
    
    vault_sync:
      enabled: true
      manual_only: false
      cron: "*/30 * * * *"  # Every 30 minutes
      description: "Sync vault files with knowledge graph"
    
    top_concepts:
      enabled: true
      manual_only: false
      cron: "0 4 * * *"  # 4 AM daily
      description: "Generate Top Concepts.md from PageRank analysis"
      metric: "pagerank"
      count: 25
      percent: null
      target_file: "Top Concepts.md"
    
    trending_topics:
      enabled: true
      manual_only: false
      cron: "0 5 * * *"  # 5 AM daily
      description: "Generate Trending Topics - <date>.md from concept mention deltas"
      window_days: 7
      count: null
      percent: 5
      min_mentions: 2
      target_file: "Trending Topics - {date}.md"
    
    concept_clustering:
      enabled: true
      manual_only: false
      cron: "0 2 * * *"  # 2 AM daily
      description: "Group related concepts into thematic clusters"
      similarity_threshold: 0.92
      min_concepts: 3
      max_concepts: 15
      algorithm: "dbscan"
      cache_ttl: 3600
      use_persistent_cache: true

# Feature flags
features:
  # Sprint 2 features
  embedding_enabled: true
  chunking_enabled: true
  pgvector_enabled: true
  
  # Future features (disabled for MVP)
  evaluation_agents: false
  concept_linking: false
  tier2_generation: false

# Vault Watcher service configuration
vault_watcher:
  # File watching configuration
  watch:
    batch_interval: 2.0  # seconds to wait before processing batched events
    max_batch_size: 50   # maximum number of events to batch
    file_patterns:
      - "*.md"           # Only watch markdown files
    ignore_patterns:
      - ".*"             # Ignore hidden files
      - "*~"             # Ignore temporary files
      - "*.tmp"          # Ignore temp files
      - ".obsidian/*"    # Ignore Obsidian metadata
  
  # RabbitMQ configuration
  rabbitmq:
    queue_name: "aclarai_dirty_blocks"
    exchange: ""         # Use default exchange
    routing_key: "aclarai_dirty_blocks"
    durable: true        # Make queue persistent
    connection_timeout: 30  # seconds
    retry_attempts: 3
    retry_delay: 5       # seconds between retries

# Development and testing
development:
  debug: false
  test_mode: false
  mock_llm: false
  mock_embedding: false